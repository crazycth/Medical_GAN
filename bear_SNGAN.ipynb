{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe4d7ee2-336f-473b-b437-1efd1655dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import utils\n",
    "from torch_mimicry.modules.layers import SNLinear\n",
    "from torch_mimicry.modules.resblocks import DBlockOptimized, DBlock, GBlock\n",
    "from torch_mimicry.nets.sngan import sngan_base\n",
    "\n",
    "from torch_mimicry.nets.gan import gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d218146-52f7-4592-b4fe-f3a3cf9b442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionSNGANGenerator128(sngan_base.SNGANBaseGenerator):\n",
    "    r\"\"\"\n",
    "    ResNet backbone generator for SNGAN.\n",
    "    Attributes:\n",
    "        nz (int): Noise dimension for upsampling.\n",
    "        ngf (int): Variable controlling generator feature map sizes.\n",
    "        bottom_width (int): Starting width for upsampling generator output to an image.\n",
    "        loss_type (str): Name of loss to use for GAN loss.\n",
    "    \"\"\"\n",
    "    def __init__(self, nz=128, ngf=1024, bottom_width=4, num_classes=2, **kwargs):\n",
    "        super().__init__(nz=nz, ngf=ngf, bottom_width=bottom_width, **kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        # Build the layers\n",
    "        self.l1 = nn.Linear(self.nz, (self.bottom_width**2) * self.ngf)\n",
    "        self.block2 = GBlock(self.ngf, self.ngf, upsample=True, num_classes=2)\n",
    "        self.block3 = GBlock(self.ngf, self.ngf >> 1, upsample=True, num_classes=2)\n",
    "        self.block4 = GBlock(self.ngf >> 1, self.ngf >> 2, upsample=True, num_classes=2)\n",
    "        self.block5 = GBlock(self.ngf >> 2, self.ngf >> 3, upsample=True, num_classes=2)\n",
    "        self.block6 = GBlock(self.ngf >> 3, self.ngf >> 4, upsample=True, num_classes=2)\n",
    "        self.b7 = nn.BatchNorm2d(self.ngf >> 4)\n",
    "        self.c7 = nn.Conv2d(self.ngf >> 4, 3, 3, 1, padding=1)\n",
    "        self.activation = nn.ReLU(True)\n",
    "\n",
    "        # Initialise the weights\n",
    "        nn.init.xavier_uniform_(self.l1.weight.data, 1.0)\n",
    "        nn.init.xavier_uniform_(self.c7.weight.data, 1.0)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        r\"\"\"\n",
    "        Feedforwards a batch of noise vectors into a batch of fake images.\n",
    "        Args:\n",
    "            x (Tensor): A batch of noise vectors of shape (N, nz).\n",
    "        Returns:\n",
    "            Tensor: A batch of fake images of shape (N, C, H, W).\n",
    "        \"\"\"\n",
    "        if y == None:\n",
    "            batch_size = x.shape[0]\n",
    "            y = torch.tensor((0,)*batch_size).to(device)\n",
    "        h = self.l1(x)\n",
    "        h = h.view(x.shape[0], -1, self.bottom_width, self.bottom_width)\n",
    "        h = self.block2(h, y)\n",
    "        h = self.block3(h, y)\n",
    "        h = self.block4(h, y)\n",
    "        h = self.block5(h, y)\n",
    "        h = self.block6(h, y)\n",
    "        h = self.b7(h)\n",
    "        h = self.activation(h)\n",
    "        h = torch.tanh(self.c7(h))\n",
    "\n",
    "        return h\n",
    "    \n",
    "    def generate_images_with_labels(self, num_images, c=None, device=None):\n",
    "        r\"\"\"\n",
    "        Generate images with possibility for conditioning on a fixed class.\n",
    "        Additionally returns labels.\n",
    "        Args:\n",
    "            num_images (int): The number of images to generate.\n",
    "            c (int): The class of images to generate. If None, generates random images.\n",
    "            device (int): The device to send the generated images to.\n",
    "        Returns:\n",
    "            tuple: Batch of generated images and their corresponding labels.\n",
    "        \"\"\"\n",
    "        if device is None:\n",
    "            device = self.device\n",
    "\n",
    "        if c is not None and c >= self.num_classes:\n",
    "            raise ValueError(\n",
    "                \"Input class to generate must be in the range [0, {})\".format(\n",
    "                    self.num_classes))\n",
    "\n",
    "        if c is None:\n",
    "            fake_class_labels = torch.randint(low=0,\n",
    "                                              high=self.num_classes,\n",
    "                                              size=(num_images,),\n",
    "                                              device=device)\n",
    "\n",
    "        else:\n",
    "            fake_class_labels = torch.randint(low=c,\n",
    "                                              high=c + 1,\n",
    "                                              size=(num_images, ),\n",
    "                                              device=device)\n",
    "\n",
    "        noise = torch.randn((num_images, self.nz), device=device)\n",
    "        fake_images = self.forward(noise, fake_class_labels)\n",
    "\n",
    "        return fake_images, fake_class_labels\n",
    "    \n",
    "    def train_step(self,\n",
    "                   real_batch,\n",
    "                   netD,\n",
    "                   optG,\n",
    "                   log_data,\n",
    "                   device=None,\n",
    "                   global_step=None,\n",
    "                   **kwargs):\n",
    "        \n",
    "        self.zero_grad()\n",
    "\n",
    "        # Get only batch size from real batch\n",
    "        batch_size = real_batch[0].shape[0]\n",
    "\n",
    "        # Produce fake images and labels\n",
    "        fake_images, fake_class_labels = self.generate_images_with_labels(\n",
    "            num_images=batch_size, device=device)\n",
    "\n",
    "        # Compute output logit of D thinking image real\n",
    "        output = netD(fake_images, fake_class_labels)\n",
    "\n",
    "        # Compute loss and backprop\n",
    "        errG = self.compute_gan_loss(output)\n",
    "\n",
    "        # Backprop and update gradients\n",
    "        errG.backward()\n",
    "        optG.step()\n",
    "\n",
    "        # Log statistics\n",
    "        log_data.add_metric('errG', errG, group='loss')\n",
    "\n",
    "        return log_data\n",
    "    \n",
    "    def generate_images(self, num_images, c=None, device=None):\n",
    "\n",
    "        if device == None:\n",
    "            device = self.device\n",
    "\n",
    "        if c != None and c >= self.num_classes:\n",
    "            raise ValueError(\n",
    "                \"Input class to generate must be in the range [0, {})\".format(\n",
    "                    self.num_classes))\n",
    "\n",
    "        if c == None:\n",
    "            fake_class_labels = torch.randint(low=0,\n",
    "                                              high=self.num_classes,\n",
    "                                              size=(num_images, ),\n",
    "                                              device=device)\n",
    "\n",
    "        else:\n",
    "            fake_class_labels = torch.randint(low=c,\n",
    "                                              high=c + 1,\n",
    "                                              size=(num_images, ),\n",
    "                                              device=device)\n",
    "\n",
    "        noise = torch.randn((num_images, self.nz), device=device)\n",
    "        fake_images = self.forward(noise, fake_class_labels)\n",
    "\n",
    "        return fake_images\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SNGANDiscriminator128(sngan_base.SNGANBaseDiscriminator):\n",
    "    r\"\"\"\n",
    "    ResNet backbone discriminator for SNGAN.\n",
    "    Attributes:\n",
    "        ndf (int): Variable controlling discriminator feature map sizes.\n",
    "        loss_type (str): Name of loss to use for GAN loss.\n",
    "    \"\"\"\n",
    "    def __init__(self, ndf=1024, **kwargs):\n",
    "        super().__init__(ndf=ndf, **kwargs)\n",
    "\n",
    "        # Build layers\n",
    "        self.block1 = DBlockOptimized(3, self.ndf >> 4)\n",
    "        self.block2 = DBlock(self.ndf >> 4, self.ndf >> 3, downsample=True)\n",
    "        self.block3 = DBlock(self.ndf >> 3, self.ndf >> 2, downsample=True)\n",
    "        self.block4 = DBlock((self.ndf >> 2) + 1024, self.ndf >> 1, downsample=True)\n",
    "        self.block5 = DBlock(self.ndf >> 1, self.ndf, downsample=True)\n",
    "        self.block6 = DBlock(self.ndf, self.ndf, downsample=False)\n",
    "        self.l7 = SNLinear(self.ndf, 1)\n",
    "        self.activation = nn.ReLU(True)\n",
    "\n",
    "        # Initialise the weights\n",
    "        nn.init.xavier_uniform_(self.l7.weight.data, 1.0)\n",
    "\n",
    "        # self.embed = nn.Embedding(2, (self.ndf>>2) * 2)\n",
    "        self.l_y = utils.spectral_norm(nn.Embedding(2, 1024))\n",
    "        \n",
    "    def train_step(self,\n",
    "                   real_batch,\n",
    "                   netG,\n",
    "                   optD,\n",
    "                   log_data,\n",
    "                   device=None,\n",
    "                   global_step=None,\n",
    "                   **kwargs):\n",
    "\n",
    "        self.zero_grad()\n",
    "        real_images, real_labels = real_batch\n",
    "        batch_size = real_images.shape[0]  # Match batch sizes for last iter\n",
    "        # Produce logits for real images\n",
    "        output_real = self.forward(real_images, real_labels)\n",
    "\n",
    "        # Produce fake images\n",
    "        fake_images = netG.generate_images(num_images=batch_size,\n",
    "                                           device=device,c=0).detach()\n",
    "\n",
    "        # Produce logits for fake images\n",
    "        output_fake = self.forward(fake_images, real_labels)\n",
    "\n",
    "        # Compute loss for D\n",
    "        errD = self.compute_gan_loss(output_real=output_real,\n",
    "                                     output_fake=output_fake)\n",
    "\n",
    "        # Backprop and update gradients\n",
    "        errD.backward()\n",
    "        optD.step()\n",
    "\n",
    "        # Compute probabilities\n",
    "        D_x, D_Gz = self.compute_probs(output_real=output_real,\n",
    "                                       output_fake=output_fake)\n",
    "\n",
    "        # Log statistics for D once out of loop\n",
    "        log_data.add_metric('errD', errD.item(), group='loss')\n",
    "        log_data.add_metric('D(x)', D_x, group='prob')\n",
    "        log_data.add_metric('D(G(z))', D_Gz, group='prob')\n",
    "\n",
    "        return log_data\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        r\"\"\"\n",
    "        Feedforwards a batch of real/fake images and produces a batch of GAN logits.\n",
    "        Args:\n",
    "            x (Tensor): A batch of images of shape (N, C, H, W).\n",
    "        Returns:\n",
    "            Tensor: A batch of GAN logits of shape (N, 1).\n",
    "        \"\"\"\n",
    "        h = x\n",
    "        h = self.block1(h)\n",
    "        h = self.block2(h)\n",
    "        h = self.block3(h)\n",
    "        if y is not None:\n",
    "            emb = self.l_y(y).unsqueeze(-1).unsqueeze(-1)\n",
    "            emb = emb.expand(emb.size(0), emb.size(1), h.size(2), h.size(3))\n",
    "            h = torch.cat((h, emb), dim=1)\n",
    "        h = self.block4(h)\n",
    "        h = self.block5(h)\n",
    "        h = self.block6(h)\n",
    "        h = self.activation(h)\n",
    "        # Global sum pooling\n",
    "        h = torch.sum(h, dim=(2, 3))\n",
    "        output = self.l7(h)\n",
    "\n",
    "        #output = self.l7(h) + torch.dot(h,y)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bbf5e93-58c5-40d3-8759-8357d6b16691",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Dataloader'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_392471/1810604832.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_mimicry\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmmc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_mimicry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msngan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mDataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm -rf /data/Medical/gan/log'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Data handling objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Dataloader'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch_mimicry as mmc\n",
    "from torch_mimicry.nets import sngan\n",
    "from Dataloader import *\n",
    "# !rm -rf /data/Medical/gan/log\n",
    "# Data handling objects\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "# dataset = mmc.datasets.load_dataset(root='./datasets', name='cifar10')\n",
    "# dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "train_dataloader = get_loader(32,r\"pic_trans_128\")\n",
    "\n",
    "# Define models and optimizers\n",
    "netG = ConditionSNGANGenerator128().to(device)\n",
    "netD = SNGANDiscriminator128().to(device)\n",
    "optD = optim.Adam(netD.parameters(), 2e-4, betas=(0.0, 0.9))\n",
    "optG = optim.Adam(netG.parameters(), 2e-4, betas=(0.0, 0.9))\n",
    "\n",
    "# Start training\n",
    "trainer = mmc.training.Trainer(\n",
    "    netD=netD,\n",
    "    netG=netG,\n",
    "    optD=optD,\n",
    "    optG=optG,\n",
    "    n_dis=5,\n",
    "    num_steps=100000,\n",
    "    lr_decay='linear',\n",
    "    dataloader=train_dataloader,\n",
    "    log_dir='./log/reality',\n",
    "    device=device,\n",
    "    vis_steps=200,\n",
    "    )\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d47dbb0-b3aa-4bb7-a7d8-9a9ad502dbea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea749c3d-81e6-44ec-a7c5-494e0fbc4262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
